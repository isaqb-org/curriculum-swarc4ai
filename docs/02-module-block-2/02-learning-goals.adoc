=== {learning-goals}

// tag::DE[]

Die Teilnehmer:Innen erreichen mit diesem Kapitel die folgenden Lernziele:

[[LZ-2-1]]
==== LZ 2-1: Einfluss der Datenschutzgesetze auf die Implemenzierung und Nutzung von KI 

Die Teilnehmer:innen kennen die Datenschutzgesetze, wie die DSGVO, und wissen wie diese die Sammlung, Verarbeitung und Speicherung von Daten durch KI-Systeme beeinflussen.

[[LZ-2-2]]
==== LZ 2-2: Ziele und Regelungen des EU AI Act

Die Teilnehmer:innen verstehen die Ziele und Regelungen des EU AI Act und wissen welchen Einfluss dies auf die Entwicklung und den Einsatz von KI-Systemen hat.

[[LZ-2-3]]
==== LZ 2-3: Einfluss des EU AI Act (Trustworthy AI) auf den Entwicklungsprozess und die Architektur des Softwaresystems

Die Teilnehmer:innen verstehen die Anforderungen des EU AI Act (Trustworthy AI) und welchen Einfluss diese Anforderungen auf den Entwicklungsprozess und die Architektur 
des Softwaresystems hat. Insbesondere kennen sie den Einfluss auf einige der folgenden Aspekte:

* Risikomanagementsystem (Risikominimierung)
* Datenqualität und Datengovernance (Qualitätsmanagementsystem)
* Erstellung und Pflege einer umfassenden technischen Dokumentation des KI-Systems
* Automatische Aufzeichnung/Logging von Events im KI-System.
* Bereitstellung klarer und verständlicher Informationen für Nutzer
* Implementierung der Maßnahmen zur menschlichen Aufsicht
* Gewährleistung eines angemessenen Maßes an Genauigkeit/Accuracy und Robustheit
* Implementierung von Maßnahmen zur Cybersicherheit

[[LZ-2-4]]
==== LZ 2-4: Klassikifaktion von KI-Systemen nach EU AI Act Risikolevel

Die Teilnehmer:innen kennen die Klassifikation von KI-Systemen nach den EU AI Act Risikolevel (verboten, hochrisikoreich, begrenzt risikoreich, niedrigrisikoreich) und wissen,
 welche regulatorischen Anforderungen jeweils gelten.

[[LZ-2-5]]
==== LZ 2-5: Urheberrechtsproblematik von KI-generierten Inhalten

Die Teilnehmer:innen verstehen die Urheberrechtsproblematik für KI-generierte Inhalte und kennen die Auswirkungen auf bestimmte Software-Lizenzmodelle sowie mögliche Umgänge damit.

[[LZ-2-6]]
==== LZ 2-6: Arten bzw. Grade der Offenheit freier ML-Modelle

Die Teilnehmer:innen überblicken verschiedene Arten bzw. Grade der Offenheit freier ML-Modelle. Das betrifft beispielsweise die Offenlegung der Daten 
und der Modellparameter.

[[LZ-2-7]]
==== LZ 2-7: Arten von Lizenzen freier ML-Modelle

Die Teilnehmer:innen kennen verschiedene Arten von Lizenzen freier ML-Modelle sowie deren Auswirkungen auf das KI-System

[[LZ-2-8]]
==== LZ 2-8: Strategien für die Einhaltung des europäischen AI-Acts und mögliche Herausforderungen

Die Teilnehmer:innen verstehen die Grundaussagen des europäischen AI-Acts (insbesondere Transparenzpflichten) und kennen Strategien 
für deren Einhaltung sowie mögliche Herausforderungen dabei.

[[LZ-2-9]]
==== LZ 2-9: Dokumentation von Modellen und Datensätzen für die Nachvollziehbarkeit und Transparenz

Die Teilnehmer:innen wissen, wie man Modelle und Datensätze effektiv dokumentiert, um Nachvollziehbarkeit und Transparenz zu gewährleisten.

[[LZ-2-10]]
==== LZ 2-10: Fallstricke hinsichtlich Security

Die Teilnehmer:innen kennen mögliche Fallstricke hinsichtlich Security.

[[LZ-2-11]]
==== LZ 2-11: Angriffsarten auf ML-Modelle

Die Teilnehmer:innen kennen typische Angriffsarten auf ML-Modelle und Beispiele dafür, besipielsweise:

* LLM-Jailbreaks durch Prompt-Engineering 
* Adversarial Attacks
* Data Poisoning
* Model Inversion & Extraction.


[[LZ-2-12]]
==== LZ 2-12: AI-Risk Minimierung Strategien

Die Teilnehmer:innen können Strategien zur AI-Risikominimierung entwickeln und anwenden. Insbesondere die folgenden Strategien kennen die Teilnehmer:innen:
* Stärkung der Robiustheit durch umfangreiche Tests
* Fehlertolerante KI-Systeme
* Transparente Entwicklung
* Erklärbare KI (explainable AI)


[[LZ-2-13]]
==== LZ 2-13: Möglichkeiten zur Absicherung gegen Angriffe (AI Security)

Die Teilnehmer:innen kennen verschiedene Möglichkeiten zur Absicherung gegen Angriffe (AI Security) und insbesondere kennen sie Möglichkeiten 
zur Integration von Sicherheitsstandards in die Architektur und können diese beim Entwurf berücksichtigen.


[[LZ-2-14]]
==== LZ 2-14: Grundproblematik und Facetten von AI-Safety

Die Teilnehmer:innen verstehen die Grundproblematik von AI-Safety und kennen die verschiedenen Facetten dazu. Insbesondere kennen die Teilnehmer:innen
spezifische Probleme wie beispielsweise "AI model risks by poisining" und  "Bias".

[[LZ-2-15]]
==== LZ 2-15: Probleme hinsichtlich Ethik, die KI-Systeme mit sich bringen können

Die Teilnehmer:innen wissen um die Probleme hinsichtlich Ethik, die KI-Systeme mit sich bringen können.

[[LZ-2-16]]
==== LZ 2-16: Ansätze zum Umgang mit ethischen Problemen

Die Teilnehmer:innen kennen Ansätze und Möglichkeiten, mit ethischen Problemen umzugehen. Dies umfasst beispielsweise  KI-Alignment (und dessen Grenzen) sowie 
die Erstellung eigener KI-Richtlinien.

[[LZ-2-17]]
==== LZ 2-17: Ethik-Leitlinien

Die Teilnehmer:innen überblicken wichtige Ethik-Leitlinien wie die „EU-Ethik-Leitlinien für vertrauenswürdige KI“ sowie die „Google AI Ethics Guidelines“.

[[LZ-2-18]]
==== LZ 2-18: Kernprinzipien zu AI Governance und Responsible AI für Unternehmen

Die Teilnehmer:innen kennen die wichtigsten Dokumente zu AI Governance, um die Kernprinzipien zu AI Governance und Responsible AI für das Unternehmen auszuarbeiten. Dies betrifft 
insbesondere die folgenden Dokumente:
* OECD AI Principles, https://oecd.ai/en/ai-principles
* The Asilomar AI Principles, https://futureoflife.org/open-letter/ai-principles/
* The IEEE Ethically Aligned Design framework, https://standards.ieee.org/wp-content/uploads/import/documents/other/ead_v2.pdf

[[LZ-2-19]]
==== LZ 2-19: Einblick in die Einrichtung von "Regulatory Sandboxes" und die mögliche rechtliche Konsequenzen bei Nichteinhaltung der Vorschriften des AI-Acts.

Die Teilnehmer:innen erhalten einen Einblick in die Einrichtung von "Regulatory Sandboxes" zur Förderung von Innovationen und 
in die möglichen rechtlichen Konsequenzen bei Nichteinhaltung der Vorschriften des AI-Acts.

[[LZ-2-20]]
==== LZ 2-20: Strukturen und Prozesse für die Steuerung und Kontrolle von KI-Systemen, um ethische und gesetzliche Anforderungen zu erfüllen.

Die Teilnehmer:innen verstehen die Strukturen und Prozesse, die zur Steuerung und Kontrolle von KI-Systemen notwendig sind, um ethische und gesetzliche Anforderungen zu erfüllen.

[[LZ-2-21]]
==== LZ 2-21: Effektive Datenverwaltung für die Sicherstellung von Qualität und Sicherheit von Daten in KI-Anwendungen

Die Teilnehmer:innen wissen, wie effektive Datenverwaltung die Qualität und Sicherheit von Daten in KI-Anwendungen sicherstellt.

[[LZ-2-22]]
==== LZ 2-22: Bedeutung und Umsetzung der Transparenzpflicht bei KI-Systemen

Die Teilnehmer:innen verstehen die Bedeutung der Transparenzpflicht bei KI-Systemen und wissen, wie sie diese in der Praxis umsetzen können.

// end::DE[]

// tag::EN[]
[[LG-2-1]]
==== LG 2-1: TBD
tbd.

[[LG-2-2]]
==== LG 2-2: TBD
tbd.
// end::EN[]
