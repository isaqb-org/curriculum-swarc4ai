=== {learning-goals}

// tag::DE[]


[[LZ-2-1]]
==== LZ 2-1: Einfluss der Datenschutzgesetze auf die Implementierung und Nutzung von KI kennen

Die Teilnehmer:innen kennen die Datenschutzgesetze wie die DSGVO und wissen, wie diese die Sammlung, Verarbeitung und Speicherung von Daten durch KI-Systeme beeinflussen.

[[LZ-2-2]]
==== LZ 2-2: Ziele und Regelungen des EU AI Act sowie deren Einfluss auf den Entwicklungsprozess und die Architektur verstehen

Die Teilnehmer:innen verstehen die Ziele und Regelungen des EU AI Act und wissen welchen Einfluss dies auf die Entwicklung und den Einsatz von KI-Systemen hat. Außerdem verstehen sie die Anforderungen des EU AI Act (Trustworthy AI) und welchen Einfluss diese Anforderungen auf den Entwicklungsprozess und die Architektur
des Softwaresystems haben. Insbesondere kennen sie den Einfluss auf einige der folgenden Aspekte:

* Risikomanagementsystem (Risikominimierung)
* Datenqualität und Daten-Governance (Qualitätsmanagementsystem)
* Erstellung und Pflege einer umfassenden technischen Dokumentation des KI-Systems
* Automatische Aufzeichnung/Logging von Events im KI-System.
* Bereitstellung klarer und verständlicher Informationen für Nutzer
* Implementierung der Maßnahmen zur menschlichen Aufsicht
* Gewährleistung eines angemessenen Maßes an Genauigkeit/Accuracy und Robustheit
* Implementierung von Maßnahmen zur Cybersicherheit


[[LZ-2-3]]
==== LZ 2-3: Klassifikation von KI-Systemen nach EU AI Act Risikolevel durchführen

Die Teilnehmer:innen kennen die Klassifikation von KI-Systemen nach den EU AI Act Risikolevel (verboten, hochrisikoreich, begrenzt risikoreich, niedrig risikoreich) und wissen,
 welche regulatorischen Anforderungen jeweils gelten.


[[LZ-2-4]]
==== LZ 2-4: Urheberrechtsproblematik von KI-generierten Inhalten einordnen

Die Teilnehmer:innen verstehen die Urheberrechtsproblematik für KI-generierte Inhalte und kennen die Auswirkungen auf bestimmte Softwarelizenzmodelle sowie mögliche Umgänge damit.

[[LZ-2-5]]
==== LZ 2-5: Arten bzw. Grade der Offenheit sowie Arten von Lizenzen freier ML-Modelle überblicken

Die Teilnehmer:innen überblicken verschiedene Arten bzw. Grade der Offenheit freier ML-Modelle. Das betrifft beispielsweise die Offenlegung der Daten
und der Modellparameter. Darüber hinaus kennen sie verschiedene Arten von Lizenzen freier ML-Modelle sowie deren Auswirkungen auf das KI-System.


[[LZ-2-6]]
==== LZ 2-6: Strategien für die Einhaltung des EU AI Acts und mögliche Herausforderungen verstehen

Die Teilnehmer:innen verstehen die Grundaussagen des EU AI Acts (insbesondere Transparenzpflichten) und kennen Strategien
für deren Einhaltung sowie mögliche Herausforderungen dabei.

[[LZ-2-7]]
==== LZ 2-7: Modelle und Datensätze für die Nachvollziehbarkeit und Transparenz dokumentieren

Die Teilnehmer:innen wissen, wie man Modelle und Datensätze effektiv dokumentiert, um Nachvollziehbarkeit und Transparenz zu gewährleisten.


[[LZ-2-8]]
==== LZ 2-8: Fallstricke hinsichtlich Security sowie Angriffsarten auf ML-Modelle kennen

Die Teilnehmer:innen kennen mögliche Fallstricke hinsichtlich Security sowie typische Angriffsarten auf ML-Modelle. Dies betrifft beispielsweise:

* LLM-Jailbreaks durch Prompt-Engineering
* Adversarial Attacks
* Data Poisoning
* Model Inversion & Extraction.



[[LZ-2-9]]
==== LZ 2-9: Strategien zur KI-Risikominimierung kennen und anwenden

Die Teilnehmer:innen wissen, wie Strategien zur KI-Risikominimierung entwickelt und angewendet werden können. Insbesondere kennen die Teilnehmer:innen die folgenden Strategien:

* Stärkung der Robustheit durch umfangreiche Tests
* Fehlertolerante KI-Systeme
* Transparente Entwicklung
* Erklärbare KI (explainable AI)


[[LZ-2-10]]
==== LZ 2-10: Möglichkeiten zur Absicherung gegen Angriffe (AI Security) anwenden

Die Teilnehmer:innen kennen verschiedene Möglichkeiten zur Absicherung gegen Angriffe (AI Security) und insbesondere kennen sie Möglichkeiten
zur Integration von Sicherheitsstandards in die Architektur und können diese beim Entwurf berücksichtigen.


[[LZ-2-11]]
==== LZ 2-11: Grundproblematik und Facetten von AI-Safety verstehen

Die Teilnehmer:innen verstehen die Grundproblematik von AI-Safety und kennen die verschiedenen Facetten dazu. Insbesondere kennen die Teilnehmer:innen
spezifische Probleme wie beispielsweise "AI model risks by poisoning" und  "Bias".

[[LZ-2-12]]
==== LZ 2-12: Ethische Probleme von KI-Systemen verstehen und Ansätze zum Umgang damit kennen

Die Teilnehmer:innen wissen um die Probleme hinsichtlich Ethik, die KI-Systeme mit sich bringen können und kennen Ansätze und Möglichkeiten, mit ethischen Problemen umzugehen. Dies umfasst beispielsweise  KI-Alignment (und dessen Grenzen) sowie die Erstellung eigener KI-Richtlinien.


[[LZ-2-13]]
==== LZ 2-13: Ethikleitlinien überblicken

Die Teilnehmer:innen überblicken wichtige Ethik-Leitlinien wie die „EU-Ethik-Leitlinien für vertrauenswürdige KI“ sowie die „Google AI Ethics Guidelines“.

[[LZ-2-14]]
==== LZ 2-14: Kernprinzipien zu AI Governance und Responsible AI für Unternehmen kennen

Die Teilnehmer:innen kennen die wichtigsten Dokumente zu AI Governance, um die Kernprinzipien zu AI Governance und Responsible AI für das Unternehmen auszuarbeiten. Dies betrifft
insbesondere die folgenden Dokumente:

* OECD AI Principles, https://oecd.ai/en/ai-principles
* The Asilomar AI Principles, https://futureoflife.org/open-letter/ai-principles/
* The IEEE Ethically Aligned Design framework, https://standards.ieee.org/wp-content/uploads/import/documents/other/ead_v2.pdf

[[LZ-2-15]]
==== LZ 2-15: Einblick in die Einrichtung von "Regulatory Sandboxes" bekommen

Die Teilnehmer:innen erhalten einen Einblick in die Einrichtung von "Regulatory Sandboxes" zur Förderung von Innovationen und
in die möglichen rechtlichen Konsequenzen bei Nichteinhaltung der Vorschriften des AI-Acts.

[[LZ-2-16]]
==== LZ 2-16: Effektive Datenverwaltung für Qualität und Sicherheit von Daten in KI-Anwendungen sicherstellen

Die Teilnehmer:innen wissen, wie effektive Datenverwaltung die Qualität und Sicherheit von Daten in KI-Anwendungen sicherstellt.


// end::DE[]

// tag::EN[]
[[LG-2-1]]
==== LG 2-1: Know the influence of Data Protection Laws on the Implementation and Use of AI

The participants know the Data Protection Laws such as the GDPR and know how they affect the collection, processing and storage of data by AI systems.

[[LG-2-2]]
==== LG 2-2: Understand the goals and regulations of the EU AI Act and their influence on the development process and architecture

The participants understand the goals and regulations of the EU AI Act and know what influence this has on the development and use of AI systems. They also understand the requirements of the EU AI Act (Trustworthy AI) and what influence these requirements have on the development process and architecture
of the software system. In particular, they know the influence on some of the following aspects:

* Risk management system (Risk Minimization)
* Data quality and data governance (Quality Management System)
* Creation and maintenance of comprehensive technical documentation of the AI-System
* Automatic recording/logging of events in the AI-System.
* Providing clear and understandable information to users
* Implementing human supervision measures
* Ensuring an appropriate level of accuracy and robustness
* Implementing cybersecurity measures

[[LG-2-3]]
==== LG 2-3: Classifying AI systems according to EU AI Act risk levels

Participants are familiar with the classification of AI systems according to the EU AI Act risk levels (Prohibited, high-risk, limited-risk, low-risk) and know which regulatory requirements apply in each case.

[[LG-2-4]]
==== LG 2-4: Classifying copyright issues for AI-generated content

Participants understand the copyright issues for AI-generated content and know the impact on certain software licensing models and how to deal with them.

[[LG-2-5]]
==== LG 2-5: Overview of types or degrees of openness and types of licenses of free ML models

The participants have an overview of different types or degrees of openness of free ML models. This concerns, for example, the disclosure of data and model parameters. In addition, they know different types of licenses for free ML models and their effects on the AI-system.

[[LG-2-6]]
==== LG 2-6: Understanding strategies for compliance with the EU AI Act and possible challenges

The participants understand the basic statements of the EU AI Act (especially transparency obligations) and know strategies for compliance with them and possible challenges.

[[LG-2-7]]
==== LG 2-7: Documenting models and data sets for traceability and transparency

The participants know how to effectively document models and data sets to ensure traceability and transparency.

[[LG-2-8]]
==== LG 2-8: Know the pitfalls regarding security and types of attacks on ML models

The participants know the possible pitfalls regarding security and typical types of attacks on ML models. This applies, for example, to:

* LLM jailbreaks through prompt engineering
* Adversarial Attacks
* Data Poisoning
* Model Inversion & Extraction.

[[LG-2-9]]
==== LG 2-9: Know and apply strategies for minimizing AI risks

The participants know how strategies for minimizing AI risks can be developed and applied. In particular, the participants know the following strategies:

* Strengthening robustness through extensive testing
* Fault-tolerant AI systems
* Transparent development
* Explainable AI

[[LG-2-10]]
==== LG 2-10: Applying options for protection against attacks (AI Security)

The participants know various options for protection against attacks (AI security) and in particular they know options for integrating security standards into the architecture and can take these into account when designing.

[[LG-2-11]]
==== LG 2-11: Understanding the basic problems and facets of AI Safety

The participants understand the basic problems of AI safety and know the various facets of it. In particular, the participants know specific problems such as "AI model risks by poisoning" and "bias".

[[LG-2-12]]
==== LG 2-12: Understanding the ethical problems of AI systems and knowing approaches to dealing with them

The participants are aware of the ethical problems that AI systems can bring with them and are aware of approaches and ways to deal with ethical problems. This includes, for example, AI alignment (and its limits) and the creation of their own AI guidelines.

[[LG-2-13]]
==== LG 2-13: Overview of ethics guidelines

The participants have an overview of important ethics guidelines such as the “EU Ethics Guidelines for Trustworthy AI” and the “Google AI Ethics Guidelines”.

[[LG-2-14]]
==== LG 2-14: Know the core principles of AI governance and responsible AI for companies

The participants know the most important documents on AI governance in order to develop the core principles of AI governance and responsible AI for the company. This concerns the following documents in particular:

* OECD AI Principles, https://oecd.ai/en/ai-principles
* The Asilomar AI Principles, https://futureoflife.org/open-letter/ai-principles/
* The IEEE Ethically Aligned Design framework, https://standards.ieee.org/wp-content/uploads/import/documents/other/ead_v2.pdf

[[LG-2-15]]
==== LG 2-15: Gain insight into the establishment of "Regulatory Sandboxes"

The participants will gain insight into the establishment of "regulatory sandboxes" to promote innovation and the possible legal consequences of non-compliance with the provisions of the AI-Act.

[[LG-2-16]]
==== LG 2-16: Effective data management to ensure the quality and security of data in AI applications

The participants know how effective data management ensures the quality and security of data in AI applications.


// end::EN[]
