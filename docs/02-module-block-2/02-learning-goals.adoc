=== {learning-goals}

// tag::DE[]


[[LZ-2-1]]
==== LZ 2-1: Einfluss der Datenschutzgesetze auf die Implementierung und Nutzung von KI kennen

Die Teilnehmer:innen kennen die Datenschutzgesetze wie die DSGVO und wissen, wie diese die Sammlung, Verarbeitung und Speicherung von Daten durch KI-Systeme beeinflussen.

[[LZ-2-2]]
==== LZ 2-2: Ziele und Regelungen des EU AI Act sowie deren Einfluss auf den Entwicklungsprozess und die Architektur verstehen

Die Teilnehmer:innen verstehen die Ziele und Regelungen des EU AI Act und wissen welchen Einfluss dies auf die Entwicklung und den Einsatz von KI-Systemen hat. Außerdem verstehen sie die Anforderungen des EU AI Act (Trustworthy AI) und welchen Einfluss diese Anforderungen auf den Entwicklungsprozess und die Architektur
des Softwaresystems haben. Insbesondere kennen sie den Einfluss auf einige der folgenden Aspekte:

* Risikomanagementsystem (Risikominimierung)
* Datenqualität und Daten-Governance (Qualitätsmanagementsystem)
* Erstellung und Pflege einer umfassenden technischen Dokumentation des KI-Systems
* Automatische Aufzeichnung/Logging von Events im KI-System.
* Bereitstellung klarer und verständlicher Informationen für Nutzer
* Implementierung der Maßnahmen zur menschlichen Aufsicht
* Gewährleistung eines angemessenen Maßes an Genauigkeit/Accuracy und Robustheit
* Implementierung von Maßnahmen zur Cybersicherheit


[[LZ-2-3]]
==== LZ 2-3: Klassifikation von KI-Systemen nach EU AI Act Risikolevel durchführen

Die Teilnehmer:innen kennen die Klassifikation von KI-Systemen nach den EU AI Act Risikolevel (verboten, hochrisikoreich, begrenzt risikoreich, niedrig risikoreich) und wissen,
 welche regulatorischen Anforderungen jeweils gelten.


[[LZ-2-4]]
==== LZ 2-4: Urheberrechtsproblematik von KI-generierten Inhalten einordnen

Die Teilnehmer:innen verstehen die Urheberrechtsproblematik für KI-generierte Inhalte und kennen die Auswirkungen auf bestimmte Softwarelizenzmodelle sowie mögliche Umgänge damit.

[[LZ-2-5]]
==== LZ 2-5: Arten bzw. Grade der Offenheit sowie Arten von Lizenzen freier ML-Modelle überblicken

Die Teilnehmer:innen überblicken verschiedene Arten bzw. Grade der Offenheit freier ML-Modelle. Das betrifft beispielsweise die Offenlegung der Daten
und der Modellparameter. Darüber hinaus kennen sie verschiedene Arten von Lizenzen freier ML-Modelle sowie deren Auswirkungen auf das KI-System.


[[LZ-2-6]]
==== LZ 2-6: Strategien für die Einhaltung des EU AI Acts und mögliche Herausforderungen verstehen

Die Teilnehmer:innen verstehen die Grundaussagen des EU AI Acts (insbesondere Transparenzpflichten) und kennen Strategien
für deren Einhaltung sowie mögliche Herausforderungen dabei.

[[LZ-2-7]]
==== LZ 2-7: Modelle und Datensätze für die Nachvollziehbarkeit und Transparenz dokumentieren

Die Teilnehmer:innen wissen, wie man Modelle und Datensätze effektiv dokumentiert, um Nachvollziehbarkeit und Transparenz zu gewährleisten.


[[LZ-2-8]]
==== LZ 2-8: Fallstricke hinsichtlich Security sowie Angriffsarten auf ML-Modelle kennen

Die Teilnehmer:innen kennen mögliche Fallstricke hinsichtlich Security sowie typische Angriffsarten auf ML-Modelle. Dies betrifft beispielsweise:

* LLM-Jailbreaks durch Prompt-Engineering
* Adversarial Attacks
* Data Poisoning
* Model Inversion & Extraction.



[[LZ-2-9]]
==== LZ 2-9: Strategien zur KI-Risikominimierung kennen und anwenden

Die Teilnehmer:innen wissen, wie Strategien zur KI-Risikominimierung entwickelt und angewendet werden können. Insbesondere kennen die Teilnehmer:innen die folgenden Strategien:

* Stärkung der Robustheit durch umfangreiche Tests
* Fehlertolerante KI-Systeme
* Transparente Entwicklung
* Erklärbare KI (explainable AI)


[[LZ-2-10]]
==== LZ 2-10: Möglichkeiten zur Absicherung gegen Angriffe (AI Security) anwenden

Die Teilnehmer:innen kennen verschiedene Möglichkeiten zur Absicherung gegen Angriffe (AI Security) und insbesondere kennen sie Möglichkeiten
zur Integration von Sicherheitsstandards in die Architektur und können diese beim Entwurf berücksichtigen.


[[LZ-2-11]]
==== LZ 2-11: Grundproblematik und Facetten von AI-Safety verstehen

Die Teilnehmer:innen verstehen die Grundproblematik von AI-Safety und kennen die verschiedenen Facetten dazu. Insbesondere kennen die Teilnehmer:innen
spezifische Probleme wie beispielsweise "AI model risks by poisoning" und  "Bias".

[[LZ-2-12]]
==== LZ 2-12: Ethische Probleme von KI-Systemen verstehen und Ansätze zum Umgang damit kennen

Die Teilnehmer:innen wissen um die Probleme hinsichtlich Ethik, die KI-Systeme mit sich bringen können und kennen Ansätze und Möglichkeiten, mit ethischen Problemen umzugehen. Dies umfasst beispielsweise  KI-Alignment (und dessen Grenzen) sowie die Erstellung eigener KI-Richtlinien.


[[LZ-2-13]]
==== LZ 2-13: Ethikleitlinien überblicken

Die Teilnehmer:innen überblicken wichtige Ethik-Leitlinien wie die „EU-Ethik-Leitlinien für vertrauenswürdige KI“ sowie die „Google AI Ethics Guidelines“.

[[LZ-2-14]]
==== LZ 2-14: Kernprinzipien zu AI Governance und Responsible AI für Unternehmen kennen

Die Teilnehmer:innen kennen die wichtigsten Dokumente zu AI Governance, um die Kernprinzipien zu AI Governance und Responsible AI für das Unternehmen auszuarbeiten. Dies betrifft
insbesondere die folgenden Dokumente:

* OECD AI Principles, https://oecd.ai/en/ai-principles
* The Asilomar AI Principles, https://futureoflife.org/open-letter/ai-principles/
* The IEEE Ethically Aligned Design framework, https://standards.ieee.org/wp-content/uploads/import/documents/other/ead_v2.pdf

[[LZ-2-15]]
==== LZ 2-15: Einblick in die Einrichtung von "Regulatory Sandboxes" bekommen

Die Teilnehmer:innen erhalten einen Einblick in die Einrichtung von "Regulatory Sandboxes" zur Förderung von Innovationen und
in die möglichen rechtlichen Konsequenzen bei Nichteinhaltung der Vorschriften des AI-Acts.

[[LZ-2-16]]
==== LZ 2-16: Effektive Datenverwaltung für Qualität und Sicherheit von Daten in KI-Anwendungen sicherstellen

Die Teilnehmer:innen wissen, wie effektive Datenverwaltung die Qualität und Sicherheit von Daten in KI-Anwendungen sicherstellt.


// end::DE[]

// tag::EN[]
[[LG-2-1]]
==== LG 2-1: Know the influence of data protection laws on the implementation and use of AI

Participants are familiar with data protection laws such as the GDPR and know how they affect the collection, processing and storage of data by AI systems.

[[LG-2-2]]
==== LG 2-2: Understand the objectives and regulations of the EU AI Act and their impact on the development process and architecture

The participants understand the objectives and regulations of the EU AI Act and know what influence this has on the development and use of AI systems. They also understand the requirements of the EU AI Act (Trustworthy AI) and what influence these requirements have on the development process and the architecture of the software system. In particular, they know the influence on some of the following aspects:

-	Risk management system (risk minimization)
-	Data quality and data governance (quality management system)
-	Creation and maintenance of comprehensive technical documentation for the AI system
-	Automatic recording/logging of events in the AI system.
-	Provision of clear and understandable information for users
-	Implementation of measures for human supervision
-	Ensuring an appropriate level of accuracy/accuracy and robustness
-	Implementation of cyber security measures


[[LG-2-3]]
==== LG 2-3: Perform classification of AI systems according to EU AI Act risk level

The participants know the classification of AI systems according to the EU AI Act risk levels (prohibited, high-risk, limited-risk, low-risk) and know which regulatory requirements apply in each case.


[[LG-2-4]]
==== LG 2-4: Classify copyright issues of AI-generated content

The participants understand the copyright issues for AI-generated content and know the effects on certain software license models and possible ways of dealing with them.


[[LG-2-5]]
==== LG 2-5: Overview of types and degrees of openness and types of licenses of free ML models

The participants gain an overview of different types and degrees of openness of free ML models. This concerns, for example, the disclosure of data and model parameters. In addition, they know different types of licenses of free ML models and their impact on the AI system.


[[LG-2-6]]
==== LG 2-6: Understand strategies for compliance with the EU AI Act and potential challenges

The participants understand the basic statements of the EU AI Act (in particular transparency obligations) and know strategies for compliance and possible challenges.


[[LG-2-7]]
==== LG 2-7: Document models and data sets for traceability and transparency

Participants know how to effectively document models and data sets to ensure traceability and transparency.


[[LG-2-8]]
==== LG 2-8: Know security pitfalls and types of attack on ML models

Participants will be familiar with possible security pitfalls and typical types of attack on ML models. This applies, for example:

-	LLM jailbreaks through prompt engineering
-	Adversarial Attacks
-	Data Poisoning
-	Model Inversion & Extraction.



[[LG-2-9]]
==== LG 2-9: Know and apply strategies for AI risk minimization

Participants know how develop and apply strategies to minimize AI risks. In particular, the participants know the following strategies:

-	Strengthening robustness through extensive testing
-	Fault-tolerant AI systems
-	Transparent development
-	Explainable AI



[[LG-2-10]]
==== LG 2-10: Apply options for protection against attacks (AI security)

Participants will be familiar with various options for protecting against attacks (AI security) and, in particular, they will be familiar with options for integrating security standards into the architecture and can take these into account in the design.


[[LG-2-11]]
==== LG 2-11: Understanding the basic issues and facets of AI safety

The participants understand the basic problems of AI safety and know the various facets of it. In particular, participants will be familiar with specific problems such as "AI model risks by poisoning" and "bias".


[[LG-2-12]]
==== LG 2-12: Understand ethical problems of AI systems and know approaches to dealing with them

Participants are aware of the ethical problems that AI systems can bring with them and know approaches and possibilities for dealing with ethical problems. This includes, for example, AI alignment (and its limits) and the creation of their own AI guidelines.


[[LG-2-13]]
==== LG 2-13: Overview of ethical guidelines

The participants review important ethics guidelines such as the "EU Ethics Guidelines for trustworthy AI" and the "Google AI Ethics Guidelines".



[[LG-2-14]]
==== LG 2-14: Know the core principles of AI governance and responsible AI for companies

The participants are familiar with the most important documents on AI governance in order to develop the core principles of AI governance and responsible AI for the company. This applies in particular to the following documents:

-	OECD AI Principles, https://oecd.ai/en/ai-principles
-	The Asilomar AI Principles, https://futureoflife.org/open-letter/ai-principles/
-	The IEEE Ethically Aligned Design framework, https://standards.ieee.org/wp-content/uploads/import/documents/other/ead_v2.pdf



[[LG-2-15]]
==== LG 2-15: Gain insight into the establishment of regulatory sandboxes

Participants will gain an insight into the establishment of regulatory sandboxes to promote innovation and the possible legal consequences of non-compliance with the provisions of the AI Act.


[[LG-2-16]]
==== LG 2-16: Ensuring effective data management for the quality and security of data in AI applications

Participants will know how effective data management ensures the quality and security of data in AI applications.


// end::EN[]
